# [CS Study] 2주차 Q&A

## **01. 캐시 메모리의 필요성과 계층 구조**

### **1.1. Q: 캐시 메모리가 필요한 이유를 메모리 계층 구조 관점에서 설명해 주세요.**

• **A:** CPU의 연산 속도와 메인 메모리(DRAM)의 접근 속도 사이에는 거대한 속도 차이(Speed Gap)가 존재합니다. CPU가 데이터를 처리하는 속도에 비해 메모리로부터 데이터를 가져오는 속도가 너무 느려 발생하는 'Memory Wall' 현상을 해결하기 위해, 그 사이에 작지만 빠른 SRAM 기반의 캐시 메모리를 두어 병목 현상을 완화합니다.

![image.png](eed9f8bf-7254-45cf-ab31-612ec3d55446.png)

## **1.2. 꼬리 질문**

### • **Q: 캐시 메모리의 용량을 무한정 늘리면 성능이 계속 좋아질까요?**

    ◦ **A:** 아닙니다. 캐시 용량이 커지면 주소를 검색하는 데 걸리는 시간(Hit Time)이 증가하고, 하드웨어 비용과 전력 소모가 급격히 늘어납니다. 따라서 적절한 크기의 캐시를 L1, L2, L3로 계층화하여 속도와 적중률의 균형을 맞춥니다.

![image.png](d21e424e-f290-4682-b88c-4978d5aa9b72.png)

## **02. LRU 교체 정책의 구현과 원리**

### **2.1. Q: LRU(Least Recently Used) 알고리즘을 자료구조로 구현한다면 어떻게 하시겠습니까?**

• **A:** 해시 테이블(Hash Table)과 이중 연결 리스트(Doubly Linked List)를 조합하여 구현하겠습니다. 해시 테이블을 통해 특정 데이터의 존재 여부를 O(1)로 탐색하고, 이중 연결 리스트를 통해 데이터의 참조 순서를 관리하여 삽입 및 삭제, 위치 재정렬 작업을 모두 O(1)에 수행할 수 있습니다.

## **2.2. 꼬리 질문**

### • **Q: 단일 연결 리스트(Singly Linked List)가 아닌 이중 연결 리스트를 사용하는 구체적인 이유는 무엇인가요?**

    ◦ **A:** 특정 노드를 중간에서 삭제하고 리스트의 맨 앞(MRU)으로 옮길 때, 이중 연결 리스트여야만 삭제할 노드의 이전 노드(prev) 주소를 즉시 알 수 있기 때문입니다. 단일 리스트는 이전 노드를 찾기 위해 처음부터 탐색해야 하므로 O(n)이 소요됩니다.

![image.png](image.png)

## **03. 캐시 적중률 극대화 및 성능 최적화**

### **3.1. Q: 캐시 적중률(Hit Rate)을 높이기 위한 구체적인 최적화 방법은 무엇인가요?**

• **A:** 소프트웨어 설계 시 지역성(Locality)을 극대화하는 패턴을 적용해야 합니다.
    1. **공간 지역성 활용:** 2차원 배열 순회 시 행 우선(Row-major) 방식을 사용하는 등 메모리 저장 순서와 일치하게 순차적으로 접근합니다.

**[코드 예시: 2차원 배열 순회]**

C

`// Good: 행 우선 순회 (Row-Major) - 공간 지역성 높음
for (int i = 0; i < N; i++) {
    for (int j = 0; j < M; j++) {
        sum += array[i][j]; // 메모리 배치 순서대로 접근
    }
}

// Bad: 열 우선 순회 (Column-Major) - 캐시 미스 유발
for (int j = 0; j < M; j++) {
    for (int i = 0; i < N; i++) {
        sum += array[i][j]; // 한 번 읽을 때마다 멀리 떨어진 주소로 점프
    }
}`

    2. **시간 지역성 활용:** 동일 데이터 블록을 집중적으로 재사용하는 루프 타일링(Loop Tiling/Blocking) 기법을 적용합니다.
    3. **데이터 패딩(Padding):** 멀티코어 환경에서 거짓 공유(False Sharing)를 방지하기 위해 독립적인 변수들을 서로 다른 캐시 라인으로 격리합니다.

C

`struct SharedData {
    int volatile counter1;
    long long padding[8]; // 64바이트 캐시 라인 경계를 맞추기 위한 패딩
    int volatile counter2;
};`

## **3.2. 관련 심화 주제**

• **Memory Alignment:** 데이터의 시작 주소를 캐시 라인 크기 배수에 맞춰 정렬하여, 하나의 데이터가 두 개의 캐시 라인에 걸쳐 발생하는 추가적인 메모리 접근을 방지하는 기법.

# 04. 부품 가격 변동의 원인 분석 및 전망

### 4.1. Q: 최근 메모리, 그래픽 카드 등 핵심 부품의 가격이 급등하는 근본적인 원인은 무엇인가요?

- **A:** 가장 큰 원인은 **AI 가속기(GPU) 생산을 위한 자원 독점**입니다.
    1. **공정의 전환:** 삼성, SK하이닉스 등 제조사가 수익성이 높은 **HBM(고대역폭 메모리)** 생산에 라인을 집중하면서, 일반 PC용 DDR5나 SSD용 NAND 플래시의 생산 비중이 줄어드는 '공급의 병목'이 발생했습니다.
    2. **VRAM 수요 폭증:** 그래픽 카드에 들어가는 비디오 메모리(GDDR) 또한 AI 서버 수요와 겹치며 제조 원가가 급격히 상승했습니다.

### 4.2. 꼬리 질문

- **Q: 메모리 가격 상승이 SSD나 그래픽 카드 외에 다른 부품에도 영향을 미치나요?**
    - **A:** 네, 메인보드와 완제품(노트북, 스마트폰) 가격에 직접적인 영향을 줍니다. 특히 고성능 메모리를 지원하기 위한 메인보드의 설계 복잡도가 올라가고, 스마트폰 제조 원가에서 메모리가 차지하는 비중이 30%를 넘어서면서 전체 IT 기기의 가격 인상을 초래하고 있습니다.
- **Q: 가격 상승을 막기 위한 기술적 대안은 없나요?**
    - **A:** 하드웨어적으로는 **CXL(Compute Express Link)** 기술을 통해 메모리 용량을 효율적으로 확장하려는 시도가 있고, 소프트웨어적으로는 메모리 점유율을 줄이는 **경량화 모델(sLLM)**이나 **효율적인 캐싱 전략**이 더욱 중요해지고 있습니다.

### 4.3. 관련 심화 주제 및 전망

- **Memory Wall과 HBM3E:** 프로세서 속도를 메모리가 따라가지 못하는 현상을 극복하기 위해 HBM3E 등 초고속 메모리 채택이 가속화되며, 이는 당분간 일반 소비자용 부품의 가격 하락을 어렵게 만드는 요인이 됩니다.
- **2026년 시장 전망:** * **단기적:** AI 서버 투자가 지속되는 한 고사양 부품의 가격은 우상향할 가능성이 높습니다.
    - **장기적:** CXL 생태계가 안착되면 메모리 풀링(Pooling)을 통해 서버급에서는 자원 효율화가 일어나겠지만, 개인 PC 시장은 'AI PC'라는 명분하에 고사양/고단가 정책이 유지될 것으로 보입니다.