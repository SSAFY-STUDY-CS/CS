# [CS Study] 2주차 Q&A

## 01. 캐시 메모리의 필요성과 계층 구조

### 1.1. Q: 캐시 메모리가 필요한 이유를 메모리 계층 구조 관점에서 설명해 주세요.

- **A:** CPU의 연산 속도와 메인 메모리(DRAM)의 접근 속도 사이에는 거대한 **속도 차이(Speed Gap)**가 존재합니다. CPU가 데이터를 처리하는 속도에 비해 메모리로부터 데이터를 가져오는 속도가 너무 느려 발생하는 **'Memory Wall'** 현상을 해결하기 위해, 그 사이에 작지만 빠른 SRAM 기반의 캐시 메모리를 두어 병목 현상을 완화합니다.

![image.png](eed9f8bf-7254-45cf-ab31-612ec3d55446.png)

### 1.2. 꼬리 질문

- **Q: 캐시 메모리의 용량을 무한정 늘리면 성능이 계속 좋아질까요?**
    - **A:** 아닙니다. 캐시 용량이 커지면 주소를 검색하는 데 걸리는 시간(**Hit Time**)이 증가하고, 하드웨어 비용과 전력 소모가 급격히 늘어납니다. 따라서 적절한 크기의 캐시를 L1, L2, L3로 계층화하여 속도와 적중률의 균형을 맞춥니다.
    
    ![image.png](d21e424e-f290-4682-b88c-4978d5aa9b72.png)
    

---

## 02. LRU 교체 정책의 구현과 원리

### 2.1. Q: LRU(Least Recently Used) 알고리즘을 자료구조로 구현한다면 어떻게 하시겠습니까?

- **A:** **해시 테이블(Hash Table)**과 **이중 연결 리스트(Doubly Linked List)**를 조합하여 구현하겠습니다. 해시 테이블을 통해 특정 데이터의 존재 여부를 $O(1)$로 탐색하고, 이중 연결 리스트를 통해 데이터의 참조 순서를 관리하여 삽입 및 삭제, 위치 재정렬 작업을 모두 **$O(1)$**에 수행할 수 있습니다.

![image.png](image.png)

### 2.2. 꼬리 질문

- **Q: 단일 연결 리스트(Singly Linked List)가 아닌 이중 연결 리스트를 사용하는 구체적인 이유는 무엇인가요?**
    - **A:** 특정 노드를 중간에서 삭제하고 리스트의 맨 앞(MRU)으로 옮길 때, 이중 연결 리스트여야만 삭제할 노드의 이전 노드(prev) 주소를 즉시 알 수 있기 때문입니다. 단일 리스트는 이전 노드를 찾기 위해 처음부터 탐색해야 하므로 $O(n)$이 소요됩니다.

---

## 03. 캐시 적중률 극대화 및 성능 최적화

### 3.1. Q: 캐시 적중률(Hit Rate)을 높이기 위한 구체적인 최적화 방법은 무엇인가요?

- **A:** 소프트웨어 설계 시 **지역성(Locality)**을 극대화하는 패턴을 적용해야 합니다.
1. **공간 지역성 활용:** 2차원 배열 순회 시 행 우선(Row-major) 방식을 사용하는 등 메모리 저장 순서와 일치하게 순차적으로 접근합니다.

C

`// Good: 행 우선 순회 (Row-Major) - 공간 지역성 높음
for (int i = 0; i < N; i++) {
    for (int j = 0; j < M; j++) {
        sum += array[i][j]; // 메모리 배치 순서대로 접근
    }
}

// Bad: 열 우선 순회 (Column-Major) - 캐시 미스 유발
for (int j = 0; j < M; j++) {
    for (int i = 0; i < N; i++) {
        sum += array[i][j]; // 한 번 읽을 때마다 멀리 떨어진 주소로 점프
    }
}`

1. **시간 지역성 활용:** 동일 데이터 블록을 집중적으로 재사용하는 루프 타일링(Loop Tiling/Blocking) 기법을 적용합니다.
2. **데이터 패딩(Padding):** 멀티코어 환경에서 거짓 공유(False Sharing)를 방지하기 위해 독립적인 변수들을 서로 다른 캐시 라인으로 격리합니다.

C

`struct SharedData {
    int volatile counter1;
    long long padding[8]; // 64바이트 캐시 라인 경계를 맞추기 위한 패딩
    int volatile counter2;
};`

### 3.2. 관련 심화 주제

- **Memory Alignment:** 데이터의 시작 주소를 캐시 라인 크기 배수에 맞춰 정렬하여, 하나의 데이터가 두 개의 캐시 라인에 걸쳐 발생하는 추가적인 메모리 접근을 방지하는 기법입니다.

---

## 04. 부품 가격 변동의 원인 분석 및 전망

### 4.1. Q: 최근 메모리, 그래픽 카드 등 핵심 부품의 가격이 급등하는 근본적인 원인은 무엇인가요?

- **A:** 가장 큰 원인은 **AI 가속기(GPU) 생산을 위한 자원 독점**입니다.
    - **공정의 전환:** 제조사가 수익성이 높은 **HBM(고대역폭 메모리)** 생산에 라인을 집중하면서, 일반 PC용 DDR5나 SSD용 NAND 플래시의 생산 비중이 줄어드는 '공급의 병목'이 발생했습니다.
    - **VRAM 수요 폭증:** 그래픽 카드용 비디오 메모리(GDDR) 또한 AI 서버 수요와 겹치며 제조 원가가 급격히 상승했습니다.

### 4.2. 꼬리 질문

- **Q: 메모리 가격 상승이 SSD나 그래픽 카드 외에 다른 부품에도 영향을 미치나요?**
    - **A:** 네, 메인보드와 완제품(노트북, 스마트폰) 가격에 직접적인 영향을 줍니다. 특히 고성능 메모리 지원을 위한 메인보드 설계 복잡도 증가 및 스마트폰 내 메모리 원가 비중 상승(약 30%)이 가격 인상을 초래합니다.
- **Q: 가격 상승을 막기 위한 기술적 대안은 없나요?**
    - **A:** 하드웨어적으로는 **CXL(Compute Express Link)** 기술을 통한 메모리 확장 시도가 있으며, 소프트웨어적으로는 **경량화 모델(sLLM)**이나 효율적인 캐싱 전략이 더욱 중요해지고 있습니다.

### 4.3. 관련 심화 주제 및 전망

- **Memory Wall과 HBM3E:** 프로세서 속도를 메모리가 따라가지 못하는 현상을 극복하기 위한 초고속 메모리 채택 가속화.
- **2026년 시장 전망:** * **단기적:** AI 서버 투자 지속으로 고사양 부품 가격 우상향 유지.
    - **장기적:** CXL 생태계 안착을 통한 서버급 자원 효율화 및 'AI PC' 명분하의 개인용 PC 고사양/고단가 정책 지속.